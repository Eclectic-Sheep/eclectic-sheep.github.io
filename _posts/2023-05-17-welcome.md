---
title: "SheepRL is out!"
author: Davide Angioni
excerpt: "Scalable, high-performance, easy-to-use, extensible, production-oriented Reinforcement Learning framework."
tags:
published: true
layout: post
image_header: cover
current: post
cover: assets/images/sheep_rl_out.png
navigation: True
class: post-template
subclass: 'post'
---

Introducing SheepRL: unleashing the Ultimate RL Framework!

SheepRL is a new framework for Reinforcement Learning. We believe that RL is the future of AI, and we want to make it accessible to everyone.

Fully written in [PyTorch](https://pytorch.org/), SheepRL is designed based on four principles:
  * **Ease of use**: SheepRL is designed to be easy to use, so that you can focus 
  * **Scalability**: SheepRL is built on top of [Lightning Fabric](https://lightning.ai/), which allows to easily scale your experiments to multiple GPUs and machines.
  * **Extensibility**: SheepRL is designed to be easily extensible, so that you can easily add new algorithms and environments.
  * **Independence**: many RL repositories tightly couple the RL algorithm with the environment, making it harder to extend them beyond the gym interface. Like other RL frameworks, SheepRL is built on top of [OpenAI Gym](https://gym.openai.com/), which provides a standard interface to interact with the environment. However, in SheepRL we developed decoupled algorithms, that are indipendent from the environment, mimicking a real production scenario.

Exisiting RL frameworks are either too complex to use, or too simple to be useful in complex settings. SheepRL is the perfect balance between the two. Inspired by [CleanRL]() but with a more modular design, SheepRL let you focus on the core aspect of the RL algorithm of choice, abstracting away secondary aspects like buffer or models implementation. At the same time, it mantains its readability, so that you can easily understand what's going on under the hood.


<img style="float: left; margin: 10px; width: 2em; height: 100px; object-fit: contain; margin-right: 20px;" src="/assets/images/apache.png">
We believe in Open Source code. That's why we release SheepRL under the [Apache 2.0 license](https://www.apache.org/licenses/LICENSE-2.0). Feel free to use it for your projects, and if you want to contribute, we are more than happy to accept your pull requests!

You can easily access the code on our [GitHub repository](https://github.com/Eclectic-Sheep/sheeprl). Simply follow the comprehensive readme guide to swiftly install and dive into the magic.

Picture this: Within a mere five minutes, you'll have your first agent trained and ready to conquer RL challenges with grace. Try it out:

<div class="two-columns-container code-flex" style="gap: 15px; margin:15px">
	<div>
		<div class="code-block with-new-line" style="opacity: 1">
			<code class="language-bash" data-lang="bash" style="opacity: 1; color: #f8f8f2; height: 250px">
git clone https://github.com/Eclectic-Sheep/sheeprl.git
cd sheeprl
python3.10 -m venv .venv
. .venv/bin/activate
pip install .
sheeprl ppo
			</code>
		</div>
	</div>
<div class="video-container shadow">
	<video id="tutorial-installation" autoplay loop muted style="margin: 0; width:600px">
		<source src="/assets/videos/tutorial.webm" type="video/webm">
	</video>
</div>
</div>

Get started with [SheepRL](https://github.com/Eclectic-Sheep/sheeprl) today!
